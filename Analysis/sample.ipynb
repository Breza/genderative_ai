{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.config.list_physical_devices()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c420371faf10dd41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_size = (512, 512)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"H:/Photos/AI/Labeled\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=327,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "852ab15881f8f893"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(labels)\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        print(f\"ax: {ax}\")\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d2769fab11ef547"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply data_augmentation to the training images.\n",
    "train_ds = train_ds.map(\n",
    "    lambda img, label: (data_augmentation(img), label),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "\n",
    "# Prefetching samples in GPU memory helps maximize GPU utilization.\n",
    "#train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "#val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "797bf5b95caa21c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
    "keras.utils.plot_model(model, show_shapes=True)\n",
    "epochs = 75\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"H:/Photos/AI/Models/save_at_{epoch}.keras\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_ds,\n",
    ")\n",
    "model = keras.models.load_model(\"H:/Photos/AI/Models/save_at_67.keras\")\n",
    "\n",
    "\n",
    "def predict_labeled_images(prediction_type):\n",
    "    print(f\"Predicting {prediction_type} images\")\n",
    "    if prediction_type == \"train\":\n",
    "        data_path = \"H:/Photos/AI/Labeled/\"\n",
    "        report_path = \"H:/Photos/AI/Labeled/labeled_predictions.csv\"\n",
    "    elif prediction_type == \"holdout\":\n",
    "        data_path = \"H:/Photos/AI/Holdout/\"\n",
    "        report_path = \"H:/Photos/AI/holdout_predictions.csv\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid prediction_type. Expected 'train' or 'holdout'.\")\n",
    "\n",
    "    image_paths = [os.path.join(dp, f) for dp, dn, filenames in os.walk(data_path) for f in filenames if\n",
    "                   os.path.splitext(f)[1] == '.jpeg']\n",
    "\n",
    "    for this_file in image_paths:\n",
    "        img = keras.utils.load_img(\n",
    "            this_file, target_size=image_size\n",
    "        )\n",
    "        img_array = keras.utils.img_to_array(img)\n",
    "        img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "        predictions = model.predict(img_array)\n",
    "\n",
    "        if 'female' in this_file.lower():\n",
    "            truth = 'Female'\n",
    "        elif 'male' in this_file.lower():\n",
    "            truth = 'Male'\n",
    "        else:\n",
    "            truth = 'Unknown'\n",
    "\n",
    "        with open(report_path, \"a\") as myfile:\n",
    "            myfile.write(f\"{this_file},{predictions[0][0]},{truth}\\n\")\n",
    "\n",
    "\n",
    "predict_labeled_images(\"train\")\n",
    "predict_labeled_images(\"holdout\")\n",
    "# Assess training predictions\n",
    "try:\n",
    "    image_size\n",
    "except NameError:\n",
    "    image_size = (512, 512)\n",
    "\n",
    "train_predictions = pd.read_csv(\"H:/Photos/AI/Labeled/labeled_predictions.csv\", header=None)\n",
    "train_predictions.columns = ['file', 'prediction', 'truth']\n",
    "train_predictions['prediction_class'] = train_predictions['prediction'].apply(lambda x: \"Female\" if x < 0.5 else \"Male\")\n",
    "train_predictions['misclassified'] = train_predictions['truth'] != train_predictions['prediction_class']\n",
    "train_predictions['misclassified'] = train_predictions['misclassified'].astype(int)\n",
    "\n",
    "#Model metrics\n",
    "print(sklearn.metrics.accuracy_score(y_true=train_predictions['truth'], y_pred=train_predictions['prediction_class']))\n",
    "print(sklearn.metrics.confusion_matrix(y_true=train_predictions['truth'], y_pred=train_predictions['prediction_class']))\n",
    "print(\n",
    "    f\"Brier score: {sklearn.metrics.brier_score_loss(y_true=train_predictions['truth'], y_prob=train_predictions['prediction'], pos_label='Male')}\")\n",
    "# Assess holdout predictions\n",
    "holdout_predictions = pd.read_csv(\"H:/Photos/AI/holdout_predictions.csv\", header=None)\n",
    "holdout_predictions.columns = ['file', 'prediction', 'truth']\n",
    "holdout_predictions['prediction_class'] = holdout_predictions['prediction'].apply(\n",
    "    lambda x: \"Female\" if x < 0.5 else \"Male\")\n",
    "holdout_predictions['prediction_confidence'] = (holdout_predictions['prediction'] - 0.5).abs()\n",
    "holdout_predictions['misclassified'] = holdout_predictions['truth'] != holdout_predictions['prediction_class']\n",
    "holdout_predictions['misclassified'] = holdout_predictions['misclassified'].astype(int)\n",
    "\n",
    "#Model metrics\n",
    "print(\n",
    "    sklearn.metrics.accuracy_score(y_true=holdout_predictions['truth'], y_pred=holdout_predictions['prediction_class']))\n",
    "print(sklearn.metrics.confusion_matrix(y_true=holdout_predictions['truth'],\n",
    "                                       y_pred=holdout_predictions['prediction_class']))\n",
    "print(\n",
    "    f\"Brier score: {sklearn.metrics.brier_score_loss(y_true=holdout_predictions['truth'], y_prob=holdout_predictions['prediction'], pos_label='Male')}\")\n",
    "\n",
    "# Find holdout images with inaccurate predictions or low confidence\n",
    "# Move them to a separate folder for manual review\n",
    "# TODO: implement this\n",
    "holdout_review = holdout_predictions.query(\"0.4 < prediction < 0.6 or misclassified == 1\").sort_values(\n",
    "    by=['misclassified', 'prediction_confidence'], ascending=[False, True]).reset_index(drop=True)\n",
    "holdout_review.to_csv(\"H:/Photos/AI/holdout_review.csv\", index=False)\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Target folder\n",
    "target_folder = 'H:/Photos/AI/working_folder'\n",
    "\n",
    "# Loop through the DataFrame and move the files\n",
    "for index, row in holdout_review.iterrows():\n",
    "    file_path = row['file']\n",
    "    try:\n",
    "        shutil.move(file_path, target_folder)\n",
    "        print(f'Moved {file_path} to {target_folder}')\n",
    "    except FileNotFoundError:\n",
    "        print(f'File {file_path} not found')\n",
    "    except Exception as e:\n",
    "        print(f'Error moving {file_path}: {e}')\n",
    "\n",
    "holdout_review\n",
    "# Classify unlabeled images\n",
    "try:\n",
    "    image_size\n",
    "except NameError:\n",
    "    image_size = (512, 512)\n",
    "\n",
    "model = keras.models.load_model(\"H:/Photos/AI/Models/save_at_67.keras\")\n",
    "\n",
    "unlabeled_directory = \"H:/Photos/AI/Unlabeled/\"\n",
    "unlabeled_paths = [os.path.join(dp, f) for dp, dn, filenames in os.walk(unlabeled_directory) for f in filenames if\n",
    "                   os.path.splitext(f)[1] == '.jpeg']\n",
    "\n",
    "for this_file in unlabeled_paths:\n",
    "    print(this_file)\n",
    "    occupation = os.path.basename(this_file).split('_')[4]\n",
    "    img = keras.utils.load_img(\n",
    "        this_file, target_size=image_size\n",
    "    )\n",
    "    img_array = keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    if predictions[0][0] < 0.5:\n",
    "        prediction_class = \"Female\"\n",
    "    else:\n",
    "        prediction_class = \"Male\"\n",
    "    with open(\"H:/Photos/AI/tf_unlabeled_predictions.csv\", \"a\") as myfile:\n",
    "        myfile.write(f\"{this_file},{occupation},{predictions[0][0]},{prediction_class}\\n\")\n",
    "# Load unlabeled predictions\n",
    "unlabeled_predictions = pd.read_csv(\"H:/Photos/AI/tf_unlabeled_predictions.csv\", header=None)\n",
    "unlabeled_predictions.columns = ['file', 'occupation', 'prediction', 'prediction_class']\n",
    "unlabeled_predictions['certainty'] = unlabeled_predictions['prediction'].apply(lambda x: abs(x - 0.5))\n",
    "plt.hist(unlabeled_predictions['prediction'], bins=20)\n",
    "unlabeled_predictions\n",
    "# Analyze gender depictions of different professions\n",
    "unlabeled_predictions['prediction_class'].groupby(unlabeled_predictions['occupation']).value_counts(normalize=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "830af244b9487626"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
